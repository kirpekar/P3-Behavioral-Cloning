{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import csv\n",
    "import matplotlib.image as im\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------- Load in the training data -----------------\n",
    "f = open('newData.csv')\n",
    "csv_f = csv.reader(f)\n",
    "Img_file_names = []\n",
    "for row in csv_f:\n",
    "  Img_file_names.append(row)\n",
    "f.close()\n",
    "\n",
    "y_train = np.zeros((len(Img_file_names)*2))\n",
    "X_train = np.zeros((len(Img_file_names)*2,55,160,3))\n",
    "\n",
    "k=0\n",
    "for i in Img_file_names:\n",
    "    tmp_img = Image.open(i[0])\n",
    "    tmp2_img = tmp_img.crop((0,50,320,160))\n",
    "    tmp2_img.thumbnail((160,55), Image.ANTIALIAS)\n",
    "\n",
    "    X_train[k,:,:,:] = (np.asarray(tmp2_img)-128.0)/128.0\n",
    "    y_train[k] = i[1]\n",
    "\n",
    "    tmp3_img = tmp2_img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    X_train[k+1,:,:,:] = (np.asarray(tmp3_img)-128.0)/128.0\n",
    "    y_train[k+1] = y_train[k]*-1.0\n",
    "    k=k+2\n",
    "\n",
    "img_rows, img_cols = 55, 160\n",
    "input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------- Model hyper parameters -----------------\n",
    "nb_epoch = 250\n",
    "batch_size = 64\n",
    "\n",
    "model = load_model('previousModel.h5')\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.000001))\n",
    "hist = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, validation_split=0.25, shuffle=True)\n",
    "print(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "model.save('newModel.h5') \n",
    "json_string = model.to_json()\n",
    "with open('newModel.json', 'w') as outfile:\n",
    "    json.dump(json_string, outfile)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
